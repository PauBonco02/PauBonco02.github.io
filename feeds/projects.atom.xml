<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Pau Boncompte - projects</title><link href="https://pauboncompte.me/" rel="alternate"/><link href="https://pauboncompte.me/feeds/projects.atom.xml" rel="self"/><id>https://pauboncompte.me/</id><updated>2025-01-01T00:00:00+09:00</updated><entry><title>EEG-Based BCI for Locomotion Intention Decoding</title><link href="https://pauboncompte.me/projects/bci-walk" rel="alternate"/><published>2025-01-01T00:00:00+09:00</published><updated>2025-01-01T00:00:00+09:00</updated><author><name>Pau Boncompte</name></author><id>tag:pauboncompte.me,2025-01-01:/projects/bci-walk</id><summary type="html">&lt;p&gt;An EEG-Based Brain-Computer Interface (BCI) for walking and turning intention decoding in a VR environment.&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article is empty.&lt;/p&gt;</content><category term="projects"/></entry><entry><title>EMG Quest: a EMG-controlled Coop Game</title><link href="https://pauboncompte.me/projects/emg-quest" rel="alternate"/><published>2025-01-01T00:00:00+09:00</published><updated>2025-01-01T00:00:00+09:00</updated><author><name>Pau Boncompte</name></author><id>tag:pauboncompte.me,2025-01-01:/projects/emg-quest</id><summary type="html">&lt;p&gt;A cooperative platformer controlled entirely by muscle signals. Two players use EMG sensors on their forearms to move their sprites through levels requiring teamwork and coordination.&lt;/p&gt;</summary><content type="html">&lt;p&gt;For &lt;a href="https://www.isct.ac.jp/en/news/o9m7vvbpu0zh"&gt;2025 Suzukakedai's Science Day&lt;/a&gt;, Yoshimura Lab opened its doors to the public to share our latest research and innovations. Visitors experienced various BCI-related technologies, including EEG-based concentration level estimation and VR environments for complex task learning like juggling. My group, however, focused on developing a platform to control a game through electromyographic (EMG) signals: &lt;strong&gt;EMG Quest&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="EMG Quest Presentation Image" src="/images/projimages/pr1_emgquest.png"&gt;&lt;/p&gt;
&lt;h2&gt;EMG Quest: Game and Controls&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;EMG Quest&lt;/strong&gt; is just a short concept game created to test the use of EMG in unity for game control. It is a 2D cooperative platformer with 4 levels in which each player controls a square (red and blue). With two sensors in the forearm per player (one in the anterior and the other in the posterior region), they can trigger 3 different actions. Considering the right arm is used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Flexing&lt;/strong&gt; the wrist to the left: &lt;strong&gt;Move Left&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Extending&lt;/strong&gt; the wrist to the right: &lt;strong&gt;Move Right&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Activating both&lt;/strong&gt; flexor and extensor muscles simultaneously: &lt;strong&gt;Jump&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To advance to the next level, both characters must be in the door with the same color as them at the same time. Some mechanics that enforce the need for cooperation include using the other player like a platform and colored tiles only solid for the player with the same color. Here you have an example from the second level.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Recording of the gameplay" src="/images/projimages/pr1_gamerecording.gif"&gt;&lt;/p&gt;
&lt;video width="60%" controls muted&gt;
  &lt;source src="/images/projimages/pr1_video.mp4" type="video/mp4"&gt;
  Your browser does not support the video tag.
&lt;/video&gt;

&lt;h2&gt;EMG sensors and data processing&lt;/h2&gt;
&lt;p&gt;We placed the sensors on the lower forearm: Channel 1 over the wrist flexor muscles and Channel 2 over the extensors. The EMG data streams directly into a Unity script that calculates the average power for each channel over 100ms intervals. Players can monitor real-time electrode activity through an in-game toggle menu, which also allows adjusting the power threshold for action activation.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Electrode location summary" src="/images/projimages/pr1_hands.png"&gt;&lt;/p&gt;
&lt;h2&gt;Reflections&lt;/h2&gt;
&lt;p&gt;EMG Quest successfully demonstrated that EMG-based game control can create engaging cooperative experiences. The system's responsiveness and the intuitive muscle-to-action mapping made it accessible even for first-time users at the Science Day. It was a great opportunity to see how people of all ages reacted to the technologies being developed in our lab, and a reminder of how accessible science can inspire the next generation.&lt;/p&gt;
&lt;p&gt;EMG-based interactive systems like this have exciting &lt;strong&gt;applications in rehabilitation&lt;/strong&gt;, where gamified muscle training can motivate patients recovering from injuries or neurological conditions. Beyond rehab, these systems can be extended to assistive technologies, human-computer interaction research, and even eSports for people with limited mobility.&lt;/p&gt;
&lt;p&gt;Future iterations could explore more complex gesture recognition (like ML-based approaches) or additional game mechanics that leverage the unique properties of EMG Control.&lt;/p&gt;
&lt;h2&gt;About this project&lt;/h2&gt;
&lt;p&gt;All the code for this project is available on Github, you can access it &lt;a href="https://github.com/PauBonco02/EMG-Controlled-Cooperative-Game"&gt;through this link&lt;/a&gt;. The repository includes the game assets, source code, and the plugins used for EMG signal recording and processing in Unity. Feel free to explore it and share any feedback!&lt;/p&gt;</content><category term="projects"/></entry><entry><title>Kanji GAN</title><link href="https://pauboncompte.me/projects/kanji-gan" rel="alternate"/><published>2025-01-01T00:00:00+09:00</published><updated>2025-01-01T00:00:00+09:00</updated><author><name>Pau Boncompte</name></author><id>tag:pauboncompte.me,2025-01-01:/projects/kanji-gan</id><summary type="html">&lt;p&gt;This is a summary&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article is empty.&lt;/p&gt;</content><category term="projects"/></entry><entry><title>Layer and Frequency-specific Task Engagement Analysis in Primary Visual Cortex</title><link href="https://pauboncompte.me/projects/lfp-visual" rel="alternate"/><published>2025-01-01T00:00:00+09:00</published><updated>2025-01-01T00:00:00+09:00</updated><author><name>Pau Boncompte</name></author><id>tag:pauboncompte.me,2025-01-01:/projects/lfp-visual</id><summary type="html">&lt;p&gt;An analysis of local field potential (LFP) signals recorded in primary visual cortex and publicly availabe by Allen Brain Insitute (Visual Behavior Neuropixels).&lt;/p&gt;</summary><content type="html">&lt;p&gt;This article is empty.&lt;/p&gt;</content><category term="projects"/></entry></feed>